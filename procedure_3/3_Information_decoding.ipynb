{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703853c5",
   "metadata": {},
   "source": [
    "# Biocomputing with Brainoware\n",
    "### Procedure 3 - Brainoware software framework\n",
    "#### 3. Information decoding\n",
    "**Author: Hongwei Cai, Huiyu Chu**  \n",
    "**Date: June 6, 2025**  \n",
    "**Description**: This part describes:\n",
    "1) how to retrieve spike properties and stimulation timing from the raw recording files.\n",
    "2) mask out spikes during stimulation artifact periods.\n",
    "3) select top N active electrodes\n",
    "4) count spikes of active electrodes, merge spike counts together as the organoid's reservoir states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb182f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speech_recognition_10hz_75mv_21680.raw.h5']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "h5py.enable_ipython_completer()\n",
    "\n",
    "path_to_rawfile = \"./2_Electrical_stimulation_and_recording_data\"\n",
    "raw_files = [f for f in os.listdir(path_to_rawfile) if f.endswith(\".raw.h5\")]\n",
    "raw_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473f2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in raw_files:\n",
    "    # -- load the raw recording file into a h5 file object -- #\n",
    "    h5_file_object = h5py.File(os.path.join(path_to_rawfile, file),'r')\n",
    "    # -- get spike information containing frame numbers, channels, and amplitude. Convert frame numbers into time in seconds -- #\n",
    "    frame_numbers = h5_file_object['data_store']['data0000']['spikes']['frameno']\n",
    "    channels = h5_file_object['data_store']['data0000']['spikes']['channel']\n",
    "    amplitudes = h5_file_object['data_store']['data0000']['spikes']['amplitude']\n",
    "    # convert integer channels to strings and append ch_ prefix to them \n",
    "    channels_as_string = channels.astype(str)\n",
    "    channels_as_string = np.char.add(\"ch_\",channels_as_string)\n",
    "    # get the initial frame number corresponding to the recording beginning\n",
    "    frame_number_start = np.min(frame_numbers)\n",
    "    # transform successive frame numbers into time in seconds relative to the beginning frame, by calculating the frame difference divided by the sampling rate (20k Hz)\n",
    "    time_after_start_frame=(frame_numbers-frame_number_start)/20000\n",
    "    \n",
    "    # -- similarly, get the stimulation event framenumbers and convert them into time in seconds relative to the beginning frame -- #\n",
    "    stimulation_timepoints = []\n",
    "    for event in h5_file_object['data_store']['data0000']['events'][:]:\n",
    "        stimulation_timepoints.append((event[0]-frame_number_start)/20000)\n",
    "    \n",
    "    # -- save spike information and stimulation timing information to separate csv files -- #\n",
    "    spikes=np.stack(\n",
    "        (time_after_start_frame,\n",
    "         channels_as_string,\n",
    "         amplitudes),\n",
    "        axis=-1)\n",
    "    df_spikes = pd.DataFrame(spikes, columns = ['time','channel','amplitude'])\n",
    "    df_sti = pd.DataFrame(stimulation_timepoints, columns = ['time'])\n",
    "    save_folder = \"./3_Information_decoding/spike_stimulation_file\"\n",
    "    spike_filename = file.replace('.raw.h5', '_spike.csv')\n",
    "    stimulation_time_filename = file.replace('.raw.h5', '_sti_time.csv')\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    df_spikes.to_csv(os.path.join(save_folder, spike_filename))\n",
    "    df_sti.to_csv(os.path.join(save_folder, stimulation_time_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511249f",
   "metadata": {},
   "source": [
    "#### PAUSE POINT \n",
    "\n",
    "The codes above concludes the retrieval of spike properties and stimulation timing from the raw recording files. The two saved csv files will be further processed to extract features for the training and prediction of the next multinomial linear regression layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87404cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle \n",
    "\n",
    "spike_stimulation_path= \"./3_Information_decoding/spike_stimulation_file/\"\n",
    "base_file_names = [f for f in os.listdir(spike_stimulation_path) if f.endswith(\"_spike.csv\")]\n",
    "# one can do batch process here, but only one example is used now to demonstrate the protocol.\n",
    "example_base_file = base_file_names[0].replace(\"_spike.csv\",\"\")\n",
    "\n",
    "spike_dataframe=pd.read_csv(spike_stimulation_path+example_base_file+'_spike.csv',usecols=[1,2,3],dtype=\"string\")\n",
    "spike_dataframe = spike_dataframe.astype({\"time\":\"float\"})\n",
    "\n",
    "stim_dataframe = pd.read_csv(spike_stimulation_path + example_base_file + \"_sti_time.csv\",usecols=[1] )\n",
    "stim_times = stim_dataframe.iloc[:, 0].values\n",
    "stim_times_str = stim_times.astype(str)\n",
    "stim_start_time = stim_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd54c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6322520, 3)\n",
      "(1567331, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## -- mask out spikes that are within [-0.0008,0.002]s of stimulation times, since these spikes can be artifacts -- ##\n",
    "\n",
    "# find the index range for each stimulation time\n",
    "idx_start = np.searchsorted(spike_dataframe['time'].values, stim_times - 0.0008)\n",
    "idx_end = np.searchsorted(spike_dataframe['time'].values, stim_times + 0.002)\n",
    "\n",
    "# create a boolean mask (all initially True)\n",
    "mask = np.ones(len(spike_dataframe), dtype=bool)\n",
    "\n",
    "# set False for indices within artifact times\n",
    "for start, end in zip(idx_start, idx_end):\n",
    "    mask[start:end] = False\n",
    "    \n",
    "# Apply mask to filter DataFrames\n",
    "spike_dataframe_no_artifact = spike_dataframe[mask]\n",
    "print(spike_dataframe.shape)\n",
    "print(spike_dataframe_no_artifact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d98258",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select top 64 active electrode by descendingly sort the spike counts of all electrodes \n",
    "top_n=64\n",
    "active_channels = spike_dataframe_no_artifact['channel'].value_counts()[:top_n].index.tolist()\n",
    "spike_dataframe_no_artifact=spike_dataframe_no_artifact.astype({'time': 'str'})\n",
    "# retrieve all spikes of active electrodes\n",
    "spike_dataframe_no_artifact_active=spike_dataframe_no_artifact[spike_dataframe_no_artifact.apply(lambda x: x.isin(active_channels)).any(axis=1)]\n",
    "spike_dataframe_no_artifact_active=spike_dataframe_no_artifact_active.astype({'time': 'float'})\n",
    "# re-organize spike information as a list per active electrode (channel)\n",
    "spike_dataframe_per_active_channel = spike_dataframe_no_artifact_active.groupby('channel',as_index=False).agg(lambda x: x.tolist())\n",
    "spike_ndarray_per_active_channel=spike_dataframe_per_active_channel['time'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13182f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_binned_spikes(spike_times,dt,count_start,count_end):\n",
    "    \"\"\"\n",
    "    Function that count spikes within time bins\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times: an array of arrays\n",
    "        an array of electrode channels. within each electrode's array is an array containing all the spike times of that electrode channel\n",
    "    dt: number (any format)\n",
    "        size of time bins\n",
    "    count_start: number (any format)\n",
    "        the start time of spike counting\n",
    "    count_end: number (any format)\n",
    "        the end time of spike counting\n",
    "    Returns\n",
    "    -------\n",
    "    count_result : a matrix of size \"number of time bins\" x \"number of channels\"\n",
    "        the number of spikes in each time bin for each channel\n",
    "    \"\"\"\n",
    "    edges=np.arange(count_start,count_end,dt) #Get edges of time bins\n",
    "    num_bins=edges.shape[0]-1 #Number of bins\n",
    "    num_channels=spike_times.shape[0] #Number of neurons\n",
    "    count_result=np.empty([num_bins,num_channels]) #Initialize array for binned neural data\n",
    "    #Count number of spikes in each bin for each neuron, and put in array\n",
    "    for i in range(num_channels):\n",
    "        count_result[:,i]=np.histogram(np.array(spike_times[i]),edges)[0]\n",
    "    return count_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2814f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## time-related parameters in the stimulation and recording section ##\n",
    "## modify if using your own datasets ##\n",
    "#   seconds_each_audio: For each audio, there are 5 seconds stimulation and recording time.\n",
    "#   audios_in_each_classes: For each class (speaker), there are 30 audios to input.\n",
    "#   classes: All classes in a classification task, in our case there are eight speakers.\n",
    "#   dt: time window size of spike count\n",
    "#   count_start_time: reference time point to start count spikes\n",
    "#   count_end_time: reference time point to end count spikes\n",
    "##\n",
    "seconds_each_audio=5\n",
    "audios_in_each_classes = 30\n",
    "classes = 8\n",
    "dt=0.01\n",
    "count_start_time = 0.006\n",
    "count_end_time = 4.105\n",
    "## define stim_start_time_per_category - an 8 timepoint list as stimulation starting times of eight classes.\n",
    "stim_start_time_per_category=np.arange(0,seconds_each_audio*audios_in_each_classes*classes,seconds_each_audio*30)\n",
    "stim_start_time_per_category = stim_start_time+stim_start_time_per_category\n",
    "## define stim_start_time_per_audioclip - an 30 timepoint list as stimulation starting time of 30 audioclips per class.\n",
    "stim_start_time_per_audioclip = np.arange(0, seconds_each_audio*audios_in_each_classes, seconds_each_audio)\n",
    "\n",
    "## store spike count data into spike_count_data list\n",
    "spike_count_data=list()\n",
    "\n",
    "## store reservoir states of all audioclips into spike_count_data\n",
    "for time_category in stim_start_time_per_category:\n",
    "    for time_audioclip in stim_start_time_per_audioclip:\n",
    "        wdw_start=time_category + time_audioclip + count_start_time\n",
    "        wdw_end=wdw_start + count_end_time\n",
    "        count_result =count_binned_spikes(spike_ndarray_per_active_channel,dt,wdw_start,wdw_end)\n",
    "        count_result_flattened = count_result.flatten()\n",
    "        spike_count_data.append(count_result_flattened)\n",
    "\n",
    "## save as pickle file for future use\n",
    "save_path = \"./3_Information_decoding\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(f'{save_path}/spike_count_data.pkl', 'wb') as f:\n",
    "    pickle.dump(spike_count_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28589c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
